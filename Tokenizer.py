#Tokenizer.py

class Tokenizer(object):
	'''
	Tokenizes string data. Also cleans special characters and delimiters:
	'[word]' '#word' 'word; word, word.'
	'''

	def __init__(self):
		pass

	def tokenize(self, data):
		pass


